{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twXX-Yk0-E0G"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import torch.optim as optim \n",
        "from torch.utils.data import DataLoader \n",
        "import torchvision.datasets as datasets \n",
        "import torchvision.transforms as transforms "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NOHaD-r-paW",
        "outputId": "74417c25-bd0c-425e-d87c-ebcebff826f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cp7_oWUg-qRl"
      },
      "outputs": [],
      "source": [
        "# Set up for getting reproducibility of result\n",
        "random.seed(1)\n",
        "np.random.seed(1)\n",
        "torch.manual_seed(1)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctJpf1vj-rOn"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "n_classes = 10\n",
        "learning_rate = 0.001\n",
        "batch_size = 64\n",
        "n_epochs = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g75eq3ih-sEz"
      },
      "outputs": [],
      "source": [
        "# Transformations\n",
        "custom_transforms = transforms.Compose([\n",
        "                                transforms.Resize((32,32)),\n",
        "                                transforms.ToTensor()\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BwuUdgUT-s4x"
      },
      "outputs": [],
      "source": [
        "# Load 'MNIST' dataset\n",
        "train_dataset = datasets.FashionMNIST(root='/content/drive/MyDrive/Datasets/FashionMNIST', train=True, \n",
        "                                                    transform=custom_transforms, download=False)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_dataset = datasets.FashionMNIST(root='/content/drive/MyDrive/Datasets/FashionMNIST', train=False, \n",
        "                                                  transform=custom_transforms, download=False)\n",
        "\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuTNPWPR_PdN",
        "outputId": "e5f6db06-ddda-4f73-ff7c-7d81ab4321c4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset FashionMNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: /content/drive/MyDrive/Datasets/FashionMNIST\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=None)\n",
              "               ToTensor()\n",
              "           )"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igfQAqev_RG3",
        "outputId": "cc4bf1b2-24a2-4879-ff26-7f928277ffb3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset FashionMNIST\n",
              "    Number of datapoints: 10000\n",
              "    Root location: /content/drive/MyDrive/Datasets/FashionMNIST\n",
              "    Split: Test\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=None)\n",
              "               ToTensor()\n",
              "           )"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUaOXM6N-t1g"
      },
      "outputs": [],
      "source": [
        "class LeNet5(nn.Module):\n",
        "    def __init__(self, n_classes):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1),\n",
        "            nn.Tanh(),\n",
        "            nn.AvgPool2d(kernel_size=2),\n",
        "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),\n",
        "            nn.Tanh(),\n",
        "            nn.AvgPool2d(kernel_size=2),\n",
        "            nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5, stride=1),\n",
        "            nn.Tanh(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(in_features=120, out_features=84),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(in_features=84, out_features=n_classes),\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "    def forward(self, X):\n",
        "        prob = self.model(X)\n",
        "        return prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZftkLf4a-vYk",
        "outputId": "631e8a14-c3c2-4ce7-c38e-4aa7f59bff35"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LeNet5(\n",
              "  (model): Sequential(\n",
              "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
              "    (1): Tanh()\n",
              "    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "    (4): Tanh()\n",
              "    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "    (6): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n",
              "    (7): Tanh()\n",
              "    (8): Flatten(start_dim=1, end_dim=-1)\n",
              "    (9): Linear(in_features=120, out_features=84, bias=True)\n",
              "    (10): Tanh()\n",
              "    (11): Linear(in_features=84, out_features=10, bias=True)\n",
              "    (12): Softmax(dim=1)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = LeNet5(n_classes=n_classes).to(device)\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9tAXu6pL-wH_"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nZOjtfU0-w2x"
      },
      "outputs": [],
      "source": [
        "for epoch in range(n_epochs):\n",
        "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
        "        # Get data to GPU\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        z_scores = model(images)\n",
        "        loss = criterion(z_scores, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient descent\n",
        "        optimizer.step()\n",
        "\n",
        "        if(batch_idx + 1) % 100 == 0:\n",
        "            print(f'Epoch {epoch+1}/{n_epochs}, Batch {batch_idx+1}, Loss: {loss.item():.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CrLzVqFg-xos"
      },
      "outputs": [],
      "source": [
        "def get_accuracy(loader, model):\n",
        "    if loader.dataset.train:\n",
        "        print('Getting accuracy on trainning data')\n",
        "    else:\n",
        "        print('Getting accuracy on testing data')\n",
        "\n",
        "    n_corrects = 0\n",
        "    n_samples = 0\n",
        "\n",
        "    # Put model to evalution mode\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            z_scores = model(images)\n",
        "\n",
        "            _, y_pred = z_scores.max(1)\n",
        "            n_corrects += (y_pred == labels).sum()\n",
        "            n_samples += y_pred.size(0)\n",
        "\n",
        "    print(f'We got {n_corrects}/{n_samples} correct')\n",
        "    print(f'Accuracy =  {float(n_corrects) / float(n_samples)*100.0:.2f}')\n",
        "    \n",
        "    # Put model to train mode\n",
        "    model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oqaI4Haz-yTu",
        "outputId": "fb1f3364-5f28-4875-92f0-97004bb132bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Getting accuracy on trainning data\n",
            "We got 54602/60000 correct\n",
            "Accuracy =  91.00\n",
            "Getting accuracy on testing data\n",
            "We got 8781/10000 correct\n",
            "Accuracy =  87.81\n"
          ]
        }
      ],
      "source": [
        "get_accuracy(train_loader, model)\n",
        "get_accuracy(test_loader, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IBrfIChZA7X4"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Fashion_MNIST_LeNet5",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}